name: factory

on:
  workflow_dispatch:               # Run button
  schedule:
    - cron: '0 21 * * *'           # every day 21:00 KST

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
    # 1) Check out repo
    - uses: actions/checkout@v4

    # 2) Install local inference lib
    - name: Install ctransformers
      run: pip install --quiet ctransformers==0.2.27 accelerate==0.28.0

    # 3) Fresh model folder (delete any file first)
    - name: Prepare model dir
      run: |
        rm -rf /tmp/model          # remove file or dir if it exists
        mkdir -p /tmp/model

    # 4) Download TinyLlama model (350 MB)
    - name: Download model
      run: |
        wget -q -O /tmp/model/tinyllama.gguf \
          https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.q4_K_M.gguf

    # 5) Pick todayâ€™s Reddit topic
    - name: Pick topic
      id: topic
      run: |
        python - <<'PY'
        import requests, random
        subs=["ADHD","GetStudying","biology"]
        hdr={"User-Agent":"snap-study-bot"}
        titles=[]
        for s in subs:
            url=f"https://www.reddit.com/r/{s}/top.json?t=day&limit=20"
            titles += [c["data"]["title"]
                       for c in requests.get(url,headers=hdr).json()["data"]["children"]]
        print(f"::set-output name=text::{random.choice(titles)}")
        PY

    # 6) Generate dashboard offline
    - name: Write dashboard
      run: |
        python - <<'PY'
        from ctransformers import AutoModelForCausalLM
        import os, textwrap, re
        model = AutoModelForCausalLM.from_pretrained(
            "/tmp/model",
            model_file="tinyllama.gguf",
            gpu_layers=0
        )
        topic="${{ steps.topic.outputs.text }}"
        prompt=textwrap.dedent(f"""
        You are a study coach.
        Write a focused Notion markdown study dashboard about "{topic}".
        Include:
        - H1 title
        - 7-day countdown table
        - daily checklist
        - habit tracker
        - reflection section
        Output ONLY markdown.
        """)
        md = model(prompt, max_new_tokens=512)
        md = re.sub(r'^.*?\n\n','', md, 1, re.S)
        open('dashboard.md','w').write(md.strip())
        PY

    # 7) Zip the file
    - name: Zip dashboard
      run: zip product.zip dashboard.md

    # 8) Hand zip back
    - uses: actions/upload-artifact@v4
      with:
        name: product
        path: product.zip
