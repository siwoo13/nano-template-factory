name: factory

on:
  workflow_dispatch:                # green “Run” button
  schedule:
    - cron: '0 21 * * *'            # every day 21:00 KST

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
    # 1) Check out this repo
    - uses: actions/checkout@v4

    # 2) Install the local inference library
    - name: Install ctransformers
      run: pip install --quiet ctransformers==0.2.27 accelerate==0.28.0

    # 3) Download TinyLlama model to a fresh folder
    - name: Download model
      run: |
        mkdir -p /tmp/model
        wget -q -O /tmp/model/tinyllama.gguf \
          https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.q4_K_M.gguf

    # 4) Pick today’s Reddit topic
    - name: Pick topic
      id: topic
      run: |
        python - <<'PY'
        import requests, random
        subs = ["ADHD", "GetStudying", "biology"]
        hdr = {"User-Agent": "snap-study-bot"}
        titles=[]
        for s in subs:
            url=f"https://www.reddit.com/r/{s}/top.json?t=day&limit=20"
            titles += [c["data"]["title"]
                       for c in requests.get(url, headers=hdr).json()["data"]["children"]]
        print(f"::set-output name=text::{random.choice(titles)}")
        PY

    # 5) Generate the dashboard completely offline
    - name: Write dashboard
      run: |
        python - <<'PY'
        from ctransformers import AutoModelForCausalLM
        import os, textwrap, re
        model = AutoModelForCausalLM.from_pretrained(
            "/tmp/model",
            model_file="tinyllama.gguf",
            gpu_layers=0              # CPU-only
        )
        topic = "${{ steps.topic.outputs.text }}"
        prompt = textwrap.dedent(f"""
        You are a study coach.
        Write a focused Notion markdown study dashboard about "{topic}".
        Include:
        - H1 title
        - 7-day countdown table
        - daily checklist
        - habit tracker
        - reflection section
        Output ONLY markdown.
        """)
        md = model(prompt, max_new_tokens=512)
        md = re.sub(r'^.*?\n\n','', md, 1, re.S)   # remove echoed prompt
        open('dashboard.md','w').write(md.strip())
        PY

    # 6) Zip the markdown
    - name: Zip dashboard
      run: zip product.zip dashboard.md

    # 7) Give you the zip as an artifact
    - uses: actions/upload-artifact@v4
      with:
        name: product
        path: product.zip
